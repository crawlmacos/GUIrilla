{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Post-processing script for GUIrilla dataset\n",
    "This script below was used to populate the GUIrilla-Task dataset after graph collection and filtering. The dataset from graph collection is saved in `raw-tasks` folder. The script processes the data and generates tasks based on the accessibility data and screenshots using OpenAI's API.\n",
    "\n",
    "It segments the images, identifies interactive elements, and generates tasks for each element.\n",
    "\n",
    "The script also saves the results in a `task_dataset` folder that was later used to publish GUIrilla-Task."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "\n",
    "# Define interactable UI element roles\n",
    "INTERACTABLE_ROLES = {\n",
    "    \"AXButton\",\n",
    "    \"AXTextField\",\n",
    "    \"AXCheckBox\",\n",
    "    \"AXRadioButton\",\n",
    "    \"AXPopUpButton\",\n",
    "    \"AXMenuButton\",\n",
    "    \"AXIncrementor\",\n",
    "    \"AXMenuItem\",\n",
    "    \"AXMenuItemCheckbox\",\n",
    "    \"AXMenuItemRadio\",\n",
    "    \"AXMenuItemTextField\",\n",
    "    \"AXScrollBar\",\n",
    "    \"AXSlider\",\n",
    "    \"AXTabGroup\",\n",
    "    \"AXTabButton\",\n",
    "    \"AXLink\",\n",
    "    \"AXDisclosureTriangle\",\n",
    "    \"AXComboBox\",\n",
    "    \"AXSearchField\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def process_elements_with_ids(element_data, draw, font, scaling_factor=1.0, parent_x=0, parent_y=0, interactable_only=True, current_id=1, id_mapping=None):\n",
    "    \"\"\"\n",
    "    Recursively process UI elements and draw rectangles with numeric IDs\n",
    "    \n",
    "    Args:\n",
    "        element_data (dict): Element data from accessibility JSON\n",
    "        draw (ImageDraw): PIL ImageDraw object\n",
    "        font (ImageFont): Font for drawing element IDs\n",
    "        scaling_factor (float): Screen scaling factor\n",
    "        parent_x (int): Parent element's x position\n",
    "        parent_y (int): Parent element's y position\n",
    "        interactable_only (bool): If True, only show interactable elements\n",
    "        current_id (int): Current numeric ID to assign\n",
    "        id_mapping (dict): Mapping of numeric IDs to original IDs\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (dict of visualized elements, mapping of numeric IDs to original IDs)\n",
    "    \"\"\"\n",
    "    visualized_elements = {}\n",
    "    if id_mapping is None:\n",
    "        id_mapping = {}\n",
    "    \n",
    "    # Use bbox directly if available, otherwise calculate from position and size\n",
    "    if \"bbox\" in element_data:\n",
    "        bbox = element_data[\"bbox\"]\n",
    "        if len(bbox) == 4:\n",
    "            role = element_data.get(\"role\", \"unknown\")\n",
    "            original_id = element_data.get(\"id\", \"\")\n",
    "            \n",
    "            # Skip non-interactable elements if interactable_only is True\n",
    "            if interactable_only and role not in INTERACTABLE_ROLES:\n",
    "                pass\n",
    "            else:\n",
    "                x1, y1, x2, y2 = bbox\n",
    "                \n",
    "                # Draw rectangle using bbox coordinates\n",
    "                top_left = (x1 * scaling_factor + parent_x, y1 * scaling_factor + parent_y)\n",
    "                bottom_right = (x2 * scaling_factor + parent_x, y2 * scaling_factor + parent_y)\n",
    "                \n",
    "                # Get color based on role\n",
    "                # color = color_for_role(role)\n",
    "                color = \"red\"\n",
    "                \n",
    "                # Draw rectangle\n",
    "                try:\n",
    "                    # Assign a numeric ID to this element\n",
    "                    numeric_id = current_id\n",
    "                    current_id += 1\n",
    "                    id_mapping[numeric_id] = original_id\n",
    "                    \n",
    "                    # Draw rectangle\n",
    "                    draw.rectangle([top_left, bottom_right], outline=color, width=2)\n",
    "                    \n",
    "                    # Get text size - using getbbox instead of textsize which is deprecated\n",
    "                    text_bbox = font.getbbox(str(numeric_id))\n",
    "                    text_width = text_bbox[2] - text_bbox[0]\n",
    "                    \n",
    "                    # Draw element ID below the box\n",
    "                    text_position = (\n",
    "                        x1 * scaling_factor + (x2 - x1) * scaling_factor / 2 - text_width / 2 + parent_x,  # Center horizontally\n",
    "                        y2 * scaling_factor + 5 + parent_y  # Position below the box\n",
    "                    )\n",
    "                    \n",
    "                    # Draw text in the correct color\n",
    "                    draw.text(text_position, str(numeric_id), fill=color, font=font)\n",
    "                    \n",
    "                    # Add element to visualized elements dict with numeric ID as key\n",
    "                    element_info = {\n",
    "                        \"original_id\": original_id,\n",
    "                        \"name\": element_data.get(\"name\", \"\"),\n",
    "                        \"role\": role,\n",
    "                        \"description\": element_data.get(\"description\", \"\"),\n",
    "                        \"role_description\": element_data.get(\"role_description\", \"\"),\n",
    "                        \"value\": element_data.get(\"value\", \"\"),\n",
    "                        \"absolute_position\": element_data.get(\"absolute_position\", \"\"),\n",
    "                        \"position\": element_data.get(\"position\", \"\"),\n",
    "                        \"size\": element_data.get(\"size\", \"\"),\n",
    "                        \"bbox\": bbox,\n",
    "                        \"visible_bbox\": element_data.get(\"visible_bbox\", bbox),\n",
    "                        \"enabled\": element_data.get(\"enabled\", False),\n",
    "                        \"children\": []\n",
    "                    }\n",
    "                    visualized_elements[numeric_id] = element_info\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error drawing rectangle for {role}: {e}\")\n",
    "    \n",
    "    # Process children recursively\n",
    "    children = element_data.get(\"children\", [])\n",
    "    for child in children:\n",
    "        child_elements, id_mapping = process_elements_with_ids(\n",
    "            child, draw, font, scaling_factor, parent_x, parent_y, interactable_only, \n",
    "            current_id=current_id, id_mapping=id_mapping\n",
    "        )\n",
    "        visualized_elements.update(child_elements)\n",
    "        \n",
    "        # Update current_id to be greater than any ID used so far\n",
    "        if id_mapping:\n",
    "            max_child_id = max(id_mapping.keys())\n",
    "            current_id = max_child_id + 1\n",
    "    \n",
    "    return visualized_elements, id_mapping\n",
    "\n",
    "# Function to load accessibility data from JSON file\n",
    "def load_accessibility_data(json_path):\n",
    "    \"\"\"\n",
    "    Load accessibility data from a JSON file\n",
    "    \n",
    "    Args:\n",
    "        json_path (str): Path to the JSON file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Parsed JSON data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading accessibility data: {e}\")\n",
    "        return {}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define colors for different UI element roles\n",
    "def color_for_role(role):\n",
    "    color = \"red\"\n",
    "    if role == \"AXButton\":\n",
    "        color = \"blue\"\n",
    "    elif role == \"AXTextField\":\n",
    "        color = \"green\"\n",
    "    elif role == \"AXStaticText\":\n",
    "        color = \"yellow\"\n",
    "    elif role == \"AXImage\":\n",
    "        color = \"purple\"\n",
    "    elif role == \"AXGroup\":\n",
    "        color = \"orange\"\n",
    "    elif role == \"AXScrollBar\":\n",
    "        color = \"brown\"\n",
    "    elif role == \"AXRow\":\n",
    "        color = \"pink\"\n",
    "    elif role == \"AXColumn\":\n",
    "        color = \"cyan\"\n",
    "    elif role == \"AXCell\":\n",
    "        color = \"magenta\"\n",
    "    elif role == \"AXTable\":\n",
    "        color = \"lightblue\"\n",
    "    elif role == \"AXOutline\":\n",
    "        color = \"lightgreen\"\n",
    "    elif role == \"AXLayoutArea\":\n",
    "        color = \"lightyellow\"\n",
    "    elif role == \"AXLayoutItem\":\n",
    "        color = \"lavender\"\n",
    "    elif role == \"AXHandle\":\n",
    "        color = \"peachpuff\"\n",
    "    elif role == \"AXSplitter\":\n",
    "        color = \"lightsalmon\"\n",
    "    elif role == \"AXIncrementor\":\n",
    "        color = \"lightpink\"\n",
    "    elif role == \"AXBusyIndicator\":\n",
    "        color = \"lightcyan\"\n",
    "    elif role == \"AXProgressIndicator\":\n",
    "        color = \"plum\"\n",
    "    elif role == \"AXToolbar\":\n",
    "        color = \"darkred\"\n",
    "    elif role == \"AXPopover\":\n",
    "        color = \"darkblue\"\n",
    "    elif role == \"AXMenu\":\n",
    "        color = \"darkgreen\"\n",
    "    elif role == \"AXMenuItem\":\n",
    "        color = \"olive\"\n",
    "    elif role == \"AXMenuBar\":\n",
    "        color = \"rebeccapurple\"\n",
    "    elif role == \"AXMenuBarItem\":\n",
    "        color = \"darkorange\"\n",
    "    elif role == \"AXMenuButton\":\n",
    "        color = \"saddlebrown\"\n",
    "    elif role == \"AXMenuItemCheckbox\":\n",
    "        color = \"palevioletred\"\n",
    "    elif role == \"AXMenuItemRadio\":\n",
    "        color = \"darkcyan\"\n",
    "    elif role == \"AXMenuItemPopover\":\n",
    "        color = \"darkmagenta\"\n",
    "    elif role == \"AXMenuItemSplitter\":\n",
    "        color = \"black\"\n",
    "    elif role == \"AXMenuItemTable\":\n",
    "        color = \"white\"\n",
    "    elif role == \"AXMenuItemTextField\":\n",
    "        color = \"lightgray\"\n",
    "    elif role == \"AXMenuItemStaticText\":\n",
    "        color = \"darkgray\"\n",
    "    elif role == \"AXMenuItemImage\":\n",
    "        color = \"salmon\"\n",
    "    elif role == \"AXMenuItemGroup\":\n",
    "        color = \"lightblue\"\n",
    "    elif role == \"AXMenuItemScrollBar\":\n",
    "        color = \"lightgreen\"\n",
    "    elif role == \"AXMenuItemRow\":\n",
    "        color = \"lightyellow\"\n",
    "    elif role == \"AXMenuItemColumn\":\n",
    "        color = \"lavender\"\n",
    "    elif role == \"AXMenuItemCell\":\n",
    "        color = \"peachpuff\"\n",
    "    elif role == \"AXMenuItemOutline\":\n",
    "        color = \"burlywood\"\n",
    "    elif role == \"AXMenuItemLayoutArea\":\n",
    "        color = \"lightpink\"\n",
    "    elif role == \"AXMenuItemLayoutItem\":\n",
    "        color = \"lightcyan\"\n",
    "    elif role == \"AXMenuItemHandle\":\n",
    "        color = \"plum\"\n",
    "    elif role == \"AXMenuItemSplitter\":\n",
    "        color = \"darkred\"\n",
    "    elif role == \"AXMenuItemIncrementor\":\n",
    "        color = \"darkblue\"\n",
    "    elif role == \"AXMenuItemBusyIndicator\":\n",
    "        color = \"darkgreen\"\n",
    "    elif role == \"AXMenuItemProgressIndicator\":\n",
    "        color = \"darkyellow\"\n",
    "    elif role == \"AXMenuItemToolbar\":\n",
    "        color = \"rebeccapurple\"\n",
    "    elif role == \"AXMenuItemPopover\":\n",
    "        color = \"darkorange\"\n",
    "    return color\n",
    "\n",
    "# Function to segment image using accessibility data\n",
    "def segment_image_with_accessibility(image_path, accessibility_data, scaling_factor=1.0, interactable_only=True):\n",
    "    \"\"\"\n",
    "    Segment an image by drawing rectangles around UI elements based on accessibility data\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        accessibility_data (dict): JSON data containing UI element information\n",
    "        scaling_factor (float): Screen scaling factor for retina displays\n",
    "        interactable_only (bool): If True, only show interactable elements\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return None, [], {}\n",
    "    \n",
    "    # Open the original image\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        # # Convert image to black and white\n",
    "        # image = image.convert('L').convert('RGBA')\n",
    "        \n",
    "        # Add padding to the image to prevent text from being cut off\n",
    "        padding = 50  # Add 50 pixels of padding on all sides\n",
    "        padded_image = Image.new(image.mode, (image.width + 2*padding, image.height + 2*padding), (255, 255, 255, 0))\n",
    "        padded_image.paste(image, (padding, padding))\n",
    "        image = padded_image\n",
    "        \n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        # Try to load a font for element IDs with size proportional to image dimensions\n",
    "        font_size = max(int(min(image.width, image.height) * 0.02), 12)  # 2% of the smaller dimension, minimum 12px\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"Arial.ttf\", font_size)\n",
    "        except IOError:\n",
    "            try:\n",
    "                font = ImageFont.truetype(\"DejaVuSans.ttf\", font_size)\n",
    "            except IOError:\n",
    "                font = ImageFont.load_default()\n",
    "        \n",
    "        # Process the accessibility data and draw rectangles with IDs\n",
    "        visualized_elements, id_mapping = process_elements_with_ids(\n",
    "            accessibility_data, draw, font, scaling_factor, interactable_only=interactable_only,\n",
    "            parent_x=padding, parent_y=padding  # Adjust for padding\n",
    "        )\n",
    "        \n",
    "        # Return the segmented image, visualized elements, and ID mapping\n",
    "        return image, visualized_elements, id_mapping\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error segmenting image: {e}\")\n",
    "        return None, [], {}\n",
    "    \n",
    "\n",
    "# Main function to segment window components\n",
    "def segment_window_components(image_path, json_path, scaling_factor=1.0, interactable_only=True):\n",
    "    \"\"\"\n",
    "    Segment window components using accessibility data\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the screenshot image\n",
    "        json_path (str): Path to the accessibility data JSON file\n",
    "        scaling_factor (float): Screen scaling factor for retina displays\n",
    "        interactable_only (bool): If True, only show interactable elements\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (segmented_image, visualized_elements, id_mapping)\n",
    "    \"\"\"\n",
    "    if not image_path or not os.path.exists(image_path):\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return None, {}, {}\n",
    "    \n",
    "    if not json_path or not os.path.exists(json_path):\n",
    "        print(f\"Accessibility data not found: {json_path}\")\n",
    "        return None, {}, {}\n",
    "    \n",
    "    # Load accessibility data\n",
    "    accessibility_data = load_accessibility_data(json_path)\n",
    "    \n",
    "    # Segment the image and get visualized elements with ID mapping\n",
    "    segmented_image, visualized_elements, id_mapping = segment_image_with_accessibility(\n",
    "        image_path, accessibility_data, scaling_factor, interactable_only\n",
    "    )\n",
    "    return segmented_image, visualized_elements, id_mapping\n",
    "\n",
    "def describe_elements(element_data):\n",
    "    \"\"\"\n",
    "    Convert element data to simple text descriptions\n",
    "    \n",
    "    Args:\n",
    "        element_data (dict): Dictionary of element dictionaries\n",
    "        \n",
    "    Returns:\n",
    "        list: List of text descriptions for each element\n",
    "    \"\"\"\n",
    "    descriptions = []\n",
    "    \n",
    "    for numeric_id, element in element_data.items():\n",
    "        parts = []\n",
    "        parts.append(f\"Element {numeric_id}\")\n",
    "        \n",
    "        if element.get('name'):\n",
    "            parts.append(f\"name: {element['name']}\")\n",
    "        \n",
    "        parts.append(f\"role: {element['role']}\")\n",
    "        \n",
    "        if element.get('description'):\n",
    "            parts.append(f\"description: {element['description']}\")\n",
    "        \n",
    "        if element.get('value') is not None:\n",
    "            parts.append(f\"value: {element['value']}\")\n",
    "        \n",
    "        descriptions.append(\" | \".join(parts))\n",
    "    \n",
    "    return descriptions\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "prompt_text = \"\"\"\n",
    "## Task\n",
    "Evaluate accessibility elements in the screenshot and identify those with good segmentation.\n",
    "\n",
    "## Segmentation Criteria\n",
    "- Box completely contains the element (no cutting through)\n",
    "- Box contains an element, not just empty space\n",
    "\n",
    "## Selection Rules\n",
    "- Choose up to 15 segmented elements\n",
    "- Prioritize icons and unique elements non text elements\n",
    "- Ignore the three window controls (close, minimize, maximize)\n",
    "- For nested elements, pick only one\n",
    "- Be extremely critical - accessibility elements are often incorrectly segmented\n",
    "- Include all the good elements, but up to 15\n",
    "\n",
    "## Output example\n",
    "Input elements: 1, 6, 3 - icons without text, 8, 9 - low quality segmentation.\n",
    "\n",
    "```json\n",
    "{\"perfect_element_ids\": [1, 6, 3, 2, 5, 4, 7, 10]}\n",
    "```\n",
    "\n",
    "Return empty array if no perfect segmentations exist: `{\"perfect_element_ids\": []}`\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "improvement_prompt = \"\"\"\n",
    "You are given:\n",
    "- An original task description for a UI interaction: {task_string}\n",
    "- A screenshot showing the full interface with a red-highlighted element\n",
    "- A cropped view focusing on just the highlighted element\n",
    "\n",
    "Your goal:\n",
    "Change the original task into a natural-language instruction FULLY in English that only involves inputting text, and precisely instructs what to do. Output an action representing a solution to this task, that is \"type\" + the exact text to input. Upon generation, it must be clear to you that the generated action is solving the previously formulated task, if not - edit the task to make it clear.\n",
    "\n",
    "Key Principles:\n",
    "- Make instructions sound like natural human instructions rather than technical commands\n",
    "- Always include specific input text (never placeholders or generic descriptions), don't interprete the text in the action, rather make sure it is clear in the task formulation that the action is solving it.\n",
    "- Consider real-world context for what the user might be trying to accomplish\n",
    "\n",
    "## Requirements\n",
    "- Each improved task must sound conversational and natural, as CONCISE as possible\n",
    "- Each action must start with \"type\" followed by the precise text to enter\n",
    "- The task should be a realistic instruction including the precise text that MUST match the input in the action\n",
    "- both task and action MUST be FULLY in English - both the formulation and the input text\n",
    "- NEVER use placeholder text like \"your email\" or \"a number\" in neither task nor action\n",
    "- Keep the focus on what the user wants to accomplish, not just the UI action\n",
    "- The task should match real-world usage patterns for the application shown\n",
    "- Do not analyze the input if it involves a comples text (for example, link, or programming line), rather be direct in the task formulation about what to input\n",
    "- the task NEVER involves clicking, pressing or selecting an element\n",
    "- the task formulation should allow a reader to have a clue about what to input, and thus, must be obviuos\n",
    "- NEVER add \"by entering it\" or \"by typing it\" to the task formulation\n",
    "\n",
    "## Format\n",
    "Return a JSON with two fields:\n",
    "- \"task\": A natural language instruction \n",
    "- \"action\": The specific typing action (always \"type\" + exact text to input)\n",
    "\n",
    "## Examples of Good Transformations\n",
    "\n",
    "Too direct → More natural:\n",
    "- ❌ \"Type John Smith in the name field\" \n",
    "- ✅ \"Put down John Smith as your full name\"\n",
    "\n",
    "Too vague → Specific but natural:\n",
    "- ❌ \"Enter your password\" \n",
    "- ✅ \"Use SecurePass456 as your account password\"\n",
    "\n",
    "Too mechanical → Goal-oriented:\n",
    "- ❌ \"Input 555-123-4567 in the phone field\" \n",
    "- ✅ \"Add your mobile number as 555-123-4567\"\n",
    "\n",
    "\n",
    "## Sample Format\n",
    "\n",
    "{{\"task\": \"Look up flights to Barcelona for your vacation\", \"action\": \"type Barcelona\"}}\n",
    "{{\"task\": \"Send Jane a message about tomorrow's meeting\", \"action\": \"type Jane\"}}\n",
    "{{\"task\": \"Use john.doe@example.com as your login email\", \"action\": \"type john.doe@example.com\"}}\n",
    "{{\"task\": \"Set your new password to BlueSky92!\", \"action\": \"type BlueSky92!\"}}\n",
    "{{\"task\": \"Search for that chocolate chip cookie recipe\", \"action\": \"type chocolate chip cookie recipe\"}}\n",
    "\n",
    "## Examples of good and bad final formulations:\n",
    "Too mysterious formulation → Clear and direct:\n",
    "- BAD : task: \"Enter coded message\", action: \"type 1234\"\n",
    "- GOOD: task: \"Enter 1234 as your coded message\", action: \"type 1234\"\n",
    "\n",
    "Non matching task and action:\n",
    "- BAD: 'task': 'Save your converted files to the Desktop folder', 'action': 'type /Users/yourname/Desktop'\n",
    "- GOOD: 'task': 'Use /Users/yourname/Desktop as your destination folder', 'action': 'type /Users/yourname/Desktop'\n",
    "\n",
    "Confusing task and action formulations → Matching formulaiton of task an action:\n",
    "- BAD :  'task': 'Enter your VISA card number to make a payment', 'action': 'type 4111111111111111'\n",
    "- GOOD:  'task': 'Use 859022930 as your VISA card number', 'action': 'type 859022930'\n",
    "\n",
    "Task formulation involves clicking → Text-based only task formulation:\n",
    "- BAD :  'task': 'Check the box labeled Include borders and shadings', 'action': 'type Include borders and shadings'\n",
    "- GOOD:  'task': 'Select Include borders and shadings as your option', 'action': 'type Include borders and shadings'\n",
    "\n",
    "## Avoid These Common Mistakes\n",
    "- ❌ Using placeholder text: \"Enter your name\" → \"Enter Maria Garcia\"\n",
    "- ❌ Being too mechanical: \"Type password in password field\" → \"Use TrustNo1 as your password\"\n",
    "- ❌ Focusing only on the UI: \"Fill the search box\" → \"Find information about electric cars\"\n",
    "- ❌ Being vague: \"Type the code\" → \"Enter 8294 as your verification code\"\n",
    "- ❌ Using impersonal language: \"Input required\" → \"Add your birthday as 03/15/1988\"\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import base64\n",
    "import pandas as pd\n",
    "import logging\n",
    "from pydantic import BaseModel\n",
    "import openai\n",
    "import json\n",
    "\n",
    "with open(\"../../config_open_ai.env\", \"r\") as f:\n",
    "    API_KEY = f.read().strip()\n",
    "\n",
    "client = openai.OpenAI(api_key=API_KEY)\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "class ElementIds(BaseModel):\n",
    "    perfect_element_ids: list[int]\n",
    "\n",
    "def get_interactive_elements(image_path):\n",
    "    # Encode the image\n",
    "    base64_image = encode_image(image_path)\n",
    "    \n",
    "    # Create a prompt with the element descriptions\n",
    "    text_input = f\"{prompt_text}\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        { \"type\": \"text\", \"text\": text_input},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            },\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            response_format={\n",
    "                'type': 'json_schema',\n",
    "                'json_schema': {\n",
    "                    \"name\": \"elements\",\n",
    "                    \"schema\": ElementIds.model_json_schema()\n",
    "                }\n",
    "            } \n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "        return result[\"perfect_element_ids\"]\n",
    "    except openai.BadRequestError as e:\n",
    "        print(f\"Error identifying interactive elements: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "prompt_task = \"\"\"\n",
    "You are given a UI screenshot, an image of the clicked UI element. \n",
    "The clicked element is highlighted in red.\n",
    "Your task is to describe the action needed to click this element.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "    0. If the element is not perfectly selected (ex. partially), the box is strangely located, or no human would do this task - return empty string.\n",
    "\n",
    "    1. The task must describe the function, not the appearance of the element.\n",
    "    For example, prefer \"Create a new document\" over \"Click the grey + button.\" Repeating the element's text is acceptable.\n",
    "\n",
    "    2. The task must be unique to this screen.\n",
    "    For example, if there are two buttons labeled \"Open,\" you must specify which \"Open\" button is meant.\n",
    "    \n",
    "    3. The task must consider the app context, but not imagine extra information.\n",
    "    For example, if the app is an image editor and the button is \"Delete,\" the better task is \"Delete an image\", not just a generic \"delete.\"\n",
    "\n",
    "    4. Use the fewest words possible without sacrificing clarity.\n",
    "\n",
    "    5. Write the task in straightforward English only.\n",
    "\n",
    "    6. Select a category for each task. Must be one of Navigation (go back), Settings (adjust volume), Files (save file), Apps (open edge), Search & Information (check weather), Media (play music), Accounts (sign in), Communication (share file), Input (enlarge font), Connectivity (connect wifi), Modes (dark mode), E-commerce (add to cart)\n",
    "\n",
    "    7. Select a category for each element. Must be one of Image, Text, Checkbox/Control, Menu item, Input field, Button, Group, Link.\n",
    "\n",
    "\n",
    "Important notes:\n",
    "\n",
    "    The click is based on accessibility information. Metadata may be incorrect or the element may not exist.\n",
    "\n",
    "    Rely primarily on the images.\n",
    "\n",
    "    The element image should show a single element with a unique function.\n",
    "    If the element is obstructed, covered by a window or pop-up, or if multiple cropped elements are shown — return an empty string.\n",
    "\n",
    "    Inspect the red box carefully: if the element is not visible, return an empty string.\n",
    "\n",
    "    If there is no red box - return empty string.\n",
    "\n",
    "Return your answer in JSON format, with no extra text.\n",
    "\n",
    "Example: {\"task\": \"Open the menu to see tutorials\", \"task_category\": \"Search & Information\", \"element_category\": \"Button\"}\n",
    "\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "import json\n",
    "import pandas as pd\n",
    "import base64\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import openai\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "class Task(BaseModel):\n",
    "    task: str\n",
    "    task_category: str\n",
    "    element_category: str\n",
    "    \n",
    "class InputTask(BaseModel):\n",
    "    task: str\n",
    "    action: str \n",
    "    \n",
    "\n",
    "def predict_task_openai(image_path=\"screenshot_bbox.jpg\", element_path=\"element.jpg\"):\n",
    "    # Path to your image\n",
    "    base64_image = encode_image(image_path)\n",
    "    base64_element = encode_image(element_path)\n",
    "    \n",
    "    text_input = f\"{prompt_task}\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        { \"type\": \"text\", \"text\": text_input},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            },\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_element}\",\n",
    "                            },\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            response_format={\n",
    "            'type': 'json_schema',\n",
    "            'json_schema': \n",
    "                {\n",
    "                    \"name\":\"task\", \n",
    "                    \"schema\": Task.model_json_schema()\n",
    "                }\n",
    "            } \n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except openai.BadRequestError:\n",
    "        print(f\"Error predicting task, bad request.\")\n",
    "        return '{\"task\": \"\", \"task_category\": \"\", \"element_category\": \"\"}'\n",
    "    \n",
    "\n",
    "def improve_task(original_task, image_path, element_path):\n",
    "    text_input = improvement_prompt.format(\n",
    "        task_string=original_task\n",
    "    )\n",
    "\n",
    "    base64_image = encode_image(image_path)\n",
    "    base64_element = encode_image(element_path)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        { \"type\": \"text\", \"text\": text_input},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            },\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_element}\",\n",
    "                            },\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            response_format={\n",
    "            'type': 'json_schema',\n",
    "            'json_schema':\n",
    "                {\n",
    "                    \"name\":\"task\",\n",
    "                    \"schema\": InputTask.model_json_schema()\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except openai.BadRequestError:\n",
    "        print(f\"Error predicting task, bad request.\")\n",
    "        return {\"task\": \"\", \"action\": \"\"}\n",
    "\n",
    "def predict_task(image_path, bbox):\n",
    "    \"\"\"Process tasks with OpenAI API and return the results.\"\"\"\n",
    "    formatted_task, task_category, element_category = \"\", \"\", \"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Check if bbox is inside the image\n",
    "    if bbox[0] < 0 or bbox[1] < 0 or bbox[2] > image.width or bbox[3] > image.height:\n",
    "        print(f\"Bounding box is not inside the image: {image_path}\")\n",
    "        return {\"formatted_task\": \"\", \"task_category\": \"\", \"element_category\": \"\"}\n",
    "\n",
    "    # Add red bounding box to image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle(bbox, outline='red', width=3)\n",
    "    \n",
    "    element_image = image.crop(bbox)\n",
    "\n",
    "    # Save temporaryimages\n",
    "    image.save(\"screenshot_bbox.jpg\")\n",
    "\n",
    "    try:\n",
    "        element_image.save(\"element.jpg\")\n",
    "    except ValueError:\n",
    "        print(f\"Bounding box is not valid for image: {image_path}\")\n",
    "        return {\"formatted_task\": \"\", \"task_category\": \"\", \"element_category\": \"\"}\n",
    "    \n",
    "    print(f\"Processing tasks for image: {image_path}\")\n",
    "\n",
    "    try: \n",
    "        prediction = json.loads(predict_task_openai())\n",
    "        print(prediction)\n",
    "        formatted_task = prediction['task']\n",
    "        task_category = prediction['task_category']\n",
    "        element_category = prediction['element_category']\n",
    "        print(f\"Extracted task: {prediction['task']} {prediction['task_category']} {prediction['element_category']}\")\n",
    "        return {\"formatted_task\": formatted_task, \"task_category\": task_category, \"element_category\": element_category}\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error predicting task: {prediction}\")\n",
    "        return {\"formatted_task\": \"\", \"task_category\": \"\", \"element_category\": \"\"}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def process_element(element_id, visualized_elements, img_cropped_path, scaling_factor):\n",
    "    \"\"\"Process a single interactive element and predict its task.\"\"\"\n",
    "    element_data = visualized_elements[element_id]\n",
    "    if \"bbox\" not in element_data:\n",
    "        return None\n",
    "    \n",
    "    bbox = element_data[\"bbox\"]\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    \n",
    "    # Predict task for this element\n",
    "    prediction = predict_task(img_cropped_path, [\n",
    "        x1 * scaling_factor, \n",
    "        y1 * scaling_factor, \n",
    "        x2 * scaling_factor, \n",
    "        y2 * scaling_factor\n",
    "    ])\n",
    "    \n",
    "    # Calculate center point for the action\n",
    "    bbox_center_x = round((x1 + x2) / 2, 2)\n",
    "    bbox_center_y = round((y1 + y2) / 2, 2)\n",
    "    action = f\"left click ({bbox_center_x}, {bbox_center_y})\"\n",
    "    \n",
    "    return {\n",
    "        \"task\": prediction['formatted_task'],\n",
    "        \"task_category\": prediction['task_category'],\n",
    "        \"element_category\": prediction['element_category'],\n",
    "        \"action\": action,\n",
    "        \"element_data\": element_data\n",
    "    }\n",
    "\n",
    "def save_image_files(screen_id, img, img_cropped, accessibility_data, segmented_image):\n",
    "    \"\"\"Save all image files and accessibility data for a task.\"\"\"\n",
    "    # Create folder for this task\n",
    "    os.makedirs(f\"task_dataset/{screen_id}\", exist_ok=True)\n",
    "    \n",
    "    # Save original image\n",
    "    img_path = f\"task_dataset/{screen_id}/image.png\"\n",
    "    img.save(img_path)\n",
    "    \n",
    "    # Save cropped image\n",
    "    img_cropped_path = f\"task_dataset/{screen_id}/image_cropped.png\"\n",
    "    img_cropped.save(img_cropped_path)\n",
    "    \n",
    "    # Save accessibility data\n",
    "    a11y_path = f\"task_dataset/{screen_id}/a11y.json\"\n",
    "    with open(a11y_path, \"w\") as f:\n",
    "        json.dump(accessibility_data, f)\n",
    "    \n",
    "    # Save segmented image\n",
    "    segmented_image_path = f\"task_dataset/{screen_id}/segmented_image.png\"\n",
    "    segmented_image.save(segmented_image_path)\n",
    "    \n",
    "    return {\n",
    "        \"img_path\": img_path,\n",
    "        \"img_cropped_path\": img_cropped_path,\n",
    "        \"a11y_path\": a11y_path,\n",
    "        \"segmented_image_path\": segmented_image_path\n",
    "    }\n",
    "\n",
    "def determine_scaling_factor(img_width):\n",
    "    \"\"\"Determine the scaling factor based on image width.\"\"\"\n",
    "    return 1 if img_width < 2000 else 2\n",
    "\n",
    "def process_task_item(item_data):\n",
    "    \"\"\"Process a single task item from the dataset.\"\"\"\n",
    "    try:\n",
    "        # Extract data\n",
    "        screen_id = item_data.id\n",
    "\n",
    "        # Check if the screen_id is already in the dataset\n",
    "        if os.path.exists(f\"task_dataset/{screen_id}\"):\n",
    "            return []\n",
    "\n",
    "        app_name = item_data.app_name\n",
    "        task = item_data.task\n",
    "        raw_task = item_data.raw_task\n",
    "        action = item_data.action\n",
    "        element_data = json.loads(item_data.element)\n",
    "        accessibility_data = json.loads(item_data.accessibility)\n",
    "        \n",
    "        # Process images\n",
    "        img = Image.open(io.BytesIO(item_data.image['bytes'])).convert(\"RGB\")\n",
    "        img_cropped = Image.open(io.BytesIO(item_data.image_cropped['bytes'])).convert(\"RGB\")\n",
    "        \n",
    "        # Determine scaling factor\n",
    "        scaling_factor = determine_scaling_factor(img.size[0])\n",
    "        \n",
    "        # Save all image files first\n",
    "        file_paths = save_image_files(\n",
    "            screen_id, \n",
    "            img, \n",
    "            img_cropped, \n",
    "            accessibility_data, \n",
    "            Image.new('RGB', img_cropped.size)  # Temporary placeholder image\n",
    "        )\n",
    "        \n",
    "        # Segment the image\n",
    "        segmented_image, visualized_elements, id_mapping = segment_image_with_accessibility(\n",
    "            file_paths[\"img_cropped_path\"], \n",
    "            accessibility_data, \n",
    "            scaling_factor=scaling_factor\n",
    "        )\n",
    "        \n",
    "        # Save the actual segmented image\n",
    "        segmented_image.save(file_paths[\"segmented_image_path\"])\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Add original task if it exists\n",
    "        if task is not None and task != \"\":\n",
    "            results.append({\n",
    "                \"screen_id\": screen_id,\n",
    "                \"app_name\": app_name,\n",
    "                \"task\": task,\n",
    "                \"raw_task\": raw_task,\n",
    "                \"action\": action,\n",
    "                \"image_path\": file_paths[\"img_path\"],\n",
    "                \"image_cropped_path\": file_paths[\"img_cropped_path\"],\n",
    "                \"segmented_image_path\": file_paths[\"segmented_image_path\"],\n",
    "                \"a11y_path\": file_paths[\"a11y_path\"],\n",
    "                \"scaling_factor\": scaling_factor,\n",
    "                \"element_data\": element_data,\n",
    "                \"original_task\": True,\n",
    "                \"task_category\": \"\",\n",
    "                \"element_category\": \"\"\n",
    "            })\n",
    "     \n",
    "        # Process interactive elements\n",
    "        if visualized_elements:\n",
    "            element_ids = get_interactive_elements(file_paths[\"segmented_image_path\"])\n",
    "            \n",
    "            for element_id in element_ids:\n",
    "                element_result = process_element(\n",
    "                    element_id, \n",
    "                    visualized_elements, \n",
    "                    file_paths[\"img_cropped_path\"], \n",
    "                    scaling_factor\n",
    "                )\n",
    "                \n",
    "                \n",
    "                if element_result:\n",
    "                    \n",
    "                    if element_result[\"element_category\"] == \"Input field\":\n",
    "                        # Get improved task\n",
    "                        improved_task = json.loads(improve_task(element_result[\"task\"], file_paths[\"img_path\"], file_paths[\"img_cropped_path\"]))\n",
    "                        element_result[\"task\"]  = improved_task[\"task\"]\n",
    "                        element_result[\"action\"] = improved_task[\"action\"]\n",
    "                        \n",
    "                    results.append({\n",
    "                        \"screen_id\": screen_id,\n",
    "                        \"app_name\": app_name,\n",
    "                        \"task\": element_result[\"task\"],\n",
    "                        \"raw_task\": \"\",\n",
    "                        \"action\": element_result[\"action\"],\n",
    "                        \"image_path\": file_paths[\"img_path\"],\n",
    "                        \"image_cropped_path\": file_paths[\"img_cropped_path\"],\n",
    "                        \"segmented_image_path\": file_paths[\"segmented_image_path\"],\n",
    "                        \"a11y_path\": file_paths[\"a11y_path\"],\n",
    "                        \"scaling_factor\": scaling_factor,\n",
    "                        \"element_data\": element_result[\"element_data\"],\n",
    "                        \"original_task\": False,\n",
    "                        \"task_category\": element_result[\"task_category\"],\n",
    "                        \"element_category\": element_result[\"element_category\"]\n",
    "                    })\n",
    "\n",
    "        # Save results to a CSV file using pandas\n",
    "        if results:\n",
    "            results_df = pd.DataFrame(results)\n",
    "            results_df = results_df[results_df['task'] != ''].reset_index(drop=True)\n",
    "            os.makedirs(f\"task_dataset/{screen_id}\", exist_ok=True)\n",
    "            results_df.to_csv(f\"task_dataset/{screen_id}/results.csv\", index=False)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing item {item_data.id}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Main processing function\n",
    "def process_parquet_files(parquet_files):\n",
    "    \"\"\"Process all parquet files and generate task data.\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for file_path in parquet_files:\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        df = pd.read_parquet(file_path, engine='pyarrow')\n",
    "        \n",
    "        for i in tqdm(range(len(df))):\n",
    "            try:\n",
    "                results = process_task_item(df.iloc[i])\n",
    "                all_data.extend(results)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing item {i} in file {file_path}: {e}\")\n",
    "\n",
    "# List of parquet files\n",
    "parquet_files = sorted(glob('raw-tasks/data/*.parquet'))\n",
    "\n",
    "# Process all files\n",
    "process_parquet_files(parquet_files)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
